{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Readme - I wrote this code on Kaggle notebook to use GPU's to ran it asotherwise it would take a lifetime to run it over CPU. So kindly run it over Kaggle. It's giving close to 99.5% percent. Here is the public notebook link - https://www.kaggle.com/anuragsharma1097/distracted-driver-detection/edit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "### Importing all the required libraries\n",
    "\n",
    "import cv2\n",
    "from glob import glob\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Dense, Activation, MaxPooling2D, Dropout, Flatten\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import RMSprop\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "labels = []\n",
    "\n",
    "def get_data(clazz):\n",
    "    \"\"\"\n",
    "    This function is used to match all the image files on Kaggle and load all the images and labels from all the files\n",
    "    and store them in separate lists of images and lables.\n",
    "    \"param clazz\": This param corresponds to labels i.e. 0, 1, 2,3 ...,8, 9 to match the filename and load the images\n",
    "                   from it.\n",
    "    \"\"\"\n",
    "    files = glob(os.path.join('..', 'input','state-farm-distracted-driver-detection','imgs', 'train', 'c' + str(clazz), '*.jpg'))\n",
    "    for file in files:\n",
    "        img = cv2.imread(file) # Reading the images\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) # Converting them to greyscale from RGB.\n",
    "        images.append(cv2.resize(img, (225,225))) # Resizing the image to 225,225 pixels\n",
    "        labels.append(clazz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling the get_date function for all the labels 0-9, to load all the files for all the classes\n",
    "\n",
    "for clazz in range(10):\n",
    "    get_data(clazz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into train and test data with train_size=0.75 and test_size=0.25\n",
    "x_train, x_test, y_train, y_test = train_test_split(images, labels, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the labels to one-hot encoding using keras.to_categorical\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "# Converting training and testing input  to numpy arrays\n",
    "x_train = np.asarray(x_train)\n",
    "x_test = np.asarray(x_test)\n",
    "\n",
    "# changing the image dimensions to (225, 225, 1) as we only need one channel.\n",
    "x_test = np.expand_dims(x_test, axis=3)\n",
    "x_train = np.expand_dims(x_train, axis=3)\n",
    "\n",
    "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploring the dataset by plotting the iput images on a (8, 8) grid just ot get a jist of how data looks.\n",
    "\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "for i in range(64):\n",
    "    ax = fig.add_subplot(8,8,i+1)\n",
    "    ax.imshow(x_train[i], cmap=plt.cm.bone)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coreating the CNN model\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Adding two convolutional layers with 32 units each, 'same' padding, 'elu' activation function.\n",
    "model.add(Conv2D(32 ,kernel_size=(3, 3), padding='same', input_shape=(225, 225, 1), strides=(1, 1), activation='elu'))\n",
    "model.add(Conv2D(32, (3, 3), activation='elu')) \n",
    "model.add(MaxPooling2D(pool_size=(2, 2))) # Using pooling layer to decrease the image size to reduce computation\n",
    "model.add(Dropout(0.25)) # Using a dropout layer with 25% probability\n",
    "\n",
    "# Adding two convolutional layers with 64 units each, 'same' padding, 'elu' activation function.\n",
    "model.add(Conv2D(64 ,kernel_size=(3, 3), padding='same', activation='elu'))\n",
    "model.add(Conv2D(64, (3, 3), activation='elu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2))) # Using pooling layer to decrease the image size to reduce computation\n",
    "model.add(Dropout(0.25)) # Using a dropout layer with 25% probability\n",
    "\n",
    "# Adding two convolutional layers with 128 units each, 'same' padding, 'elu' activation function.\n",
    "model.add(Conv2D(128 ,kernel_size=(3, 3), padding='same', activation='elu'))\n",
    "model.add(Conv2D(128, (3, 3), activation='elu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))# Using pooling layer to decrease the image size to reduce computation\n",
    "model.add(Dropout(0.25)) # Using a dropout layer with 25% probability\n",
    "\n",
    "model.add(Flatten()) # Flattening the image array\n",
    "model.add(Dense(256, activation='elu')) # Dense layer with 256 units and 'elu' activation function\n",
    "model.add(Dropout(0.25)) # Using a dropout layer with 25% probability\n",
    "\n",
    "# Using the output layer with 10 units as we have 10 labels and 'softmax' activation function\n",
    "model.add(Dense(10, activation='softmax')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary() # Printing the model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the RMSprop with learning rate of '0.0001' and '1e-6' decay. Tried using Adam optimizer as well but it \n",
    "# reduced the accuracy to 98.3% percent from 99.5%\n",
    "\n",
    "opt = RMSprop(lr=0.0001, decay=1e-6)\n",
    "\n",
    "# Compiling the the model using the 'categorical_crossentropy' loss fucntion and accuracy as the metrics\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the model with 10 epochs and batch_size of 50\n",
    "model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=10, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the accuracy which is close to 99.5%. Let me if you need to confirma and I can share the screenshot. \n",
    "\n",
    "_, acc = model.evaluate(x_test, y_test, verbose=10)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
